\chapter{Common solutions}
In this chapter we will try to summarize the most common techniques for solving the rendering equation in the presence of participating media. Many methods are used today and it's way beyond the scope of this thesis to do a proper summary of them, so only widely used methods related to the context of this thesis were picked.
\section{ Rasterization}
Rather than talking about game solutions, where is the main goal to render everything real time and physical accuracy of lighting is less important than plausible smooth graphics, we will have a look on rasterzation used in off-line rendering.
\\
\\
Rasterization comes as a nature choice, when it comes to particle rendering. It's key benefit is that the whole scene geometry doesn't have to fit into the RAM \footnote{Computer main random access memory.}, in the cost of linear rendering complexity. Because list of primitives, be it points, lines or triangles, is rasterized one by one in the frame-buffer.

\begin{minipage}{\linewidth}
      \begin{minipage}{0.45\linewidth}
          \begin{figure}[H]
              \includegraphics[width=\linewidth]{images/halfanglenvidia.png}
              \captionsetup{width=\linewidth}
              \caption[Half axis angle particle sorting and rendering.]{Illustration of the half axis angle determination for single particle sorting pass. Source \cite{NVIDIA}.}\label{fig:HAA}
          \end{figure}
      \end{minipage}
      \hspace{0.05\linewidth}
      \begin{minipage}{0.45\linewidth}
          \begin{figure}[H]
              \includegraphics[width=\linewidth]{\cestaImg nvidiasmokeparticles.jpg}
              \captionsetup{width=\linewidth}
              \caption[Nvidia smoke particle demo. Source \cite{NVIDIA}.]{This image has been rendered using multiple shadow maps for particle direct illumination on gpu. Source \cite{NVIDIA}.}\label{fig:NVS}
          \end{figure}
      \end{minipage}
  \end{minipage}
  \\
  \\
 \noindent{
Almost all the algorithms widely used rely on the same kind of preprocessing stage. The particles should be ideally sorted from the furtherest to the closest, and rasterized in this order, so that the alpha blending works correctly. Which is quite costly, considering we should sort millions of particles twice. Once for the camera view and once for the shadow map generation light view. To partially overcome this issue a half-angle axis sorting can be used, where we sort particles along a half angle axis between the camera and the light only once as can be seen on fig. \ref{fig:HAA}.
}
\\
\\
Also shadow map containing only a nearest depth is practically useless when used with millions of partially transparent particles. To cope with this we can either rasterize the particles in the common layer batches for camera view and light view to sample progressively reducing transmittance as used in nVidia demo fig. \ref{fig:NVS}. 
\\
\\
Or we can eventually use deep shadow maps \cite{LokDSM}, where is the occlusion function of depth\footnote{The function is usually represented as lookup table containing [depth,transmittance] tuples.} instead of a single value per pixel in the case of regular shadow maps. This approach allows pre-filtering\footnote{Object can occlude only partial part of the pixel, thus adding only appropriate amount of occlusion in incident depth.} which leads to suppression of both depth and aliasing artifacts commonly seen in shadow map renderings.
\\

\noindent{
Even tough only single scattering volume interaction can be modeled this way, it's very popular method widely used in the VFX industry, because it can handle very efficiently even billions of particles as can be seen on fig. \ref{fig:KRAK}. 
}

\myFigure{0.95}{\cestaImg krakatoa.jpg}{Krakatoa particle and volume rendering.}{Examples of rasterization Krakatoa particle render used in feature film productions \cite{KRAK} .}{fig:KRAK}

\section{Raytracing}
Another very popular set of methods for solving rendering equation is based on ray-tracing. Instead of rasterizing (drawing) directly visible elements, concept of ray scene interaction is used, where set of rays originating either in camera or in light are shoot into the scene space to gather light information. Which is way more flexible than rasterization, in the terms of complex light scene interaction and logarithmic cost of visibility computation\footnote{Not all the elements of the scene have to be usually intersected. And the complexity of ray element intersection in the present of volume partitioning acceleration structure such as KD or BVH tree is logarithmic.}.
\\
\\
The flexibility unfortunately goes in hand with an additional cost of acceleration structure build and usage for a ray primitive intersection. That's why these algorithms are so memory demanding. Because majority of the scene has to be loaded in the RAM for efficient visibility calculation.
\\
\\
In the following subsections the key ray-tracing concepts and methods are briefly overviewed.  

% great page for latex equation typing http://www.codecogs.com/latex/eqneditor.php
%Quasi Monte Carlo equation
%\begin{equation*}
%\int _{I^{S}}f(x)dx\approx\frac{1}{N}\sum_{i=1}^{N}f(x_{i})),
%\end{equation*}
%\int _{I^{S}}f(x)dx\approx\frac{1}{N}\sum_{i=1}^{N}f(x_{i})),

\subsection{Visibility evaluation}
The key aspect of ray-tracing volumes is the radiance integration between two points in space. Without the participating media the visibility is only a matter of ray surface intersection, the first object intersected by the ray is simply considered visible. In the presence of participating media we have to also consider transmittance change along the ray and in-scattered radiance along the path. For now we will stay with the transmittance evaluation only. In homogeneous media a simple analytic solution exists. Since $\kappa_t$ is constant we just evaluate the $  \tau(x_{0},x)=e^{-\kappa_t*\left | x_{0}\rightarrow x \right |}$.
\\
\\
In order to compute transmittance in non-homogeneous media according the eq. \ref{eq:TAU}, we can use ray-marching technique. Which evaluates the extinction coefficient of the media $\kappa_t(x_{v})\text{, in a point }x_{v}=\vec{r}*v$, where $\vec{r}$ is a ray direction and $v$ is some chosen step size. Ideally we should choose very small $v$, which would inevitably lead to render time increase. This technique also introduces bias to our estimate, which we would like to ideally avoid.
\\
\\
%tohle patri spis do pravdepodobnosti scateringu freeflyght distance ale tvrdi ze tak pocitaji transmitanci, je tam adaptive stepp size
Another technique known as Woodcock tracking \footnote{ The idea was used in neutron transport theory under different names mainly as delta tracking. Nevertheless Woodcock tracking is used in CG community to promote the original author.}. The idea is quite simple, if we know the maximum extinction coefficient of our media (which we very often know) we could sample the media according this coefficient more densely then needed and then randomly choose if to take another sample or return. This approach is based on the probability theory behind the light particle interaction.

pbrt single scattering
can support procedural volumes and any type of lighting

\subsection{Unbiased methods}

\myFigure{0.55}{\cestaImg temp.jpg}{Unbiased ray-tracing methods.}{Examples of unbiased ray-tracing methods, from left \ita{path tracing, light tracing, bidirectional path tracing}. The principle is pictured on the top raw and example renderings are in the bottom one.}{fig:UNBRT}

Path tracing, light tracing fig. \ref{fig:UNBRT}
Plus and cons - very slow no caching re-computation of visibility factor

\subsection{Biased methods}

\cite{jarosz08thesis} %jarosz thesis irradiance caching
irradiance caching, Photon tracing, final gather ...
Plus and cons

%tahle sekce ve finale byt nema
\section{HardCode}
\subsection{Monte Carlo Ray-tracing}
Monte Carlo (from now on, abbreviated to MC) methods are commonly used for solving rendering equation, because robust analytical solution to the integral equation is not known. Since MC methods are based on numerical integration using random sampling and we can't integrate infinitely, these methods leads us to an approximate solution. The error introduced by the lack of samples is called variance and exhibits itself as a noise in the rendered image. The main benefit is that the convergence to the ground truth solution is independent on the problem domain and variance decreases linearly\footnote{Reduction rate is $(\frac{1}{n})$, where $n$ is number of samples}, the down side is that the standard deviation decreases in a $\frac{1}{\sqrt{n}}$. This means that, in order to half the noise level in the image, we have to generate four times more samples.

\subsection{Bidirectional path tracing}
However, bidirectional path tracing still fails to render specular reflection, refractions of caustics. This is because directly connecting a point on a specular surface to the camera always results in zero contribution to the image.


\subsection{Photon mapping}
Photon mapping is two pass method, first introduced by Jensen in the \cite{Jensen:1996} paper. It's loosely based on a bidirectional Monte Carlo ray tracing. Instead of direct light - camera path connecting, the flux carrying light paths of length at least two are cached in the form of so called "photons". These imaginary particles are shoot in the first pass of the algorithm and end up in one of the two photon map acceleration structures. Caustic photon map holds photons created by direct specular reflection/refraction paths from light. Or they end up in the indirect photon map structure, which holds photons after an interaction with the diffuse surface.

In the second rendering pass the camera rays are shot. The direct lighting component is evaluated just like in the case of distributed ray tracing, but the indirect lighting is evaluated using e photon maps. The caustic photon map is evaluated directly, because caustic effects usually exhibit strong sharp features, while the slowly changing indirect lighting is evaluated using final gathering the indirect photon map.


